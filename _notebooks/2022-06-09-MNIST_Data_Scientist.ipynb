{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cd34bff",
   "metadata": {},
   "source": [
    "# Federated Learning (Data Scientist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba3010",
   "metadata": {},
   "source": [
    "*Published by* <a href = \"https://www.leow.ca\"> by Leo Wei </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b946f1",
   "metadata": {},
   "source": [
    "Before reading the rest of this blog, make sure you have the <a href = \"https://de-fellows.github.io/RexCoding/2022/06/09/MNIST_Data_Owner.html\"> Federated Learning (Data Owner)</a> open side by side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdde69b",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "* [What is federated learning?](#intro)\n",
    "    * [Tools that made federated learning possible](#tools)\n",
    "* [Installation](#installation)\n",
    "* [Pysyft Duet (Data scientist)](#duet)\n",
    "    * [Duet Basics](#basics)\n",
    "    * [MNIST with Duet](#mnist)\n",
    "        * [Part 1: Connect to Remote Duet Server](#part1)\n",
    "        * [Part 2: Setting up Model and Data](#part2)\n",
    "        * [Part 3: Training](#part3)\n",
    "        * [Part 4: Inference](#part4)\n",
    "* [Where to next](#next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac39a4b",
   "metadata": {},
   "source": [
    "## What is federated learning? <a class =\"anchor\" id =\"intro\"/>\n",
    "In the world of evergrowing data in every industry, data is becoming more scarce due to security and privacy reasons. This makes our jobs as data scientists harder as companies and institutions are holding onto their data for security and competitive reasons. Nowadays, a lot of important data are sensitive personal information, things like health, and happiness, etc. Our ability to solve problems is limited because we can't access the existing data. \n",
    "\n",
    "<br/>\n",
    "Federated learning is a machine learning setting where multiple clients(data owners) can come together and solve a machine learning problem, under the coordination of a central server(data scientist). Each data owner's data is stored  locally, and will not be access without direct permission. Instead of traditionally training on one machine locally, the network is sent to all clients and trained on multiple clients simultaneously. After training, the machine learning model would aggregate the model updates from the trained model from the clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f7459",
   "metadata": {},
   "source": [
    "There are many situations in which federated learning can be used to solve problems. One use case of this is in the  healthcare industry: <br/>\n",
    "Breast cancer is a something that is faced by 1 in 8 woman. It is actually very treatable if it is detected early enough in a mammogram. However, this is where the problem lies. In detection, there is a 1 in 4 chance that the radiologist will give false positive or false negative, and with AI, the detection accuracy is even worse with the accuracy being 1 in 3 false positive or false negative. This is most likely due to our models not having enough training data, the amount of training data we have is less than <0.1% of the world's mammography images. These data we need are stored across thousands of organizations, and acquiring data from each organization is extremely difficult as some organizations will protect patients' privacy not mentioning the bureaucracy involved in signing contracts and risk management with thousands of different companies and organizations. <br/>\n",
    "\n",
    "Federated learning could tackle this problem by having a massive federated data network, each data center(hospital, research center, etc) would act as a client. We, the data scientist is able to send our machine learning model to each client, and have the client train the model locally, and finally update the global model by exchanging the weighted average of the weights. (FedAvg Algorithm)\n",
    "\n",
    "![source: Nividia](https://blogs.nvidia.com/wp-content/uploads/2019/10/federated_learning_animation_still_white.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72042f5",
   "metadata": {},
   "source": [
    "### Advantages of federated learning\n",
    "- Data never leaves the owner's device, privacy of sensitive data is stored. \n",
    "- Federated learning allows devices like cell phones to train collectively, thus saving computation and memory on the server, data scientist's side.\n",
    "- Data owners are more comfortable with sharing their data, and leading to better machine learning models.\n",
    "\n",
    "### Limitations of federated learning\n",
    "- Communication, latency is often the bottleneck for federated learning. \n",
    "- Variability in client hardware, it is often the case that after each round of training, the server will have to wait for the slower devices to report back with their trained weights. These stragglers often slow down the network, often times, the network just drop the stragglers, but is that a good approach? Does that mean the model will cater more towards people with faster phones?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc9423",
   "metadata": {},
   "source": [
    "## Tools that made federated learning possible <a class = \"anchor\" id= \"tools\"/>\n",
    "\n",
    "### 1. Remote execution\n",
    "Remote execution is a core tool used in federated learning. Instead of downloading the data from the clients and then performing machine learning on it, remote execution allows you to use the client's data without their data leaving their devices.\n",
    "\n",
    "### 2. Search and example data \n",
    "If we are executing functions remotely, how can we do data science without seeing the data? <br/>\n",
    "With tools such as sample data, we can feature engineer the data without actually seeing the full data. We can request from the data owners to allow us to see a small sub sample of the data in order for us to get a better understanding of the data. \n",
    "\n",
    "### 3. Differential privacy \n",
    "How do we query again a database without revealing too much information about its privacy data? <br/>\n",
    "Our goal is to achieve perfect privacy, meaning that the output of our query is the same between this database and any identical database with one row removed or replaced. However, achieving this is incredibly difficult and the way in which we attempt to achieve this is by adding a certain level of noise to the data.\n",
    "\n",
    "### 4. Secure multi-party computation\n",
    "The idea of secure multi-party computation is that multiple people can combine their private inputs to compute a function, without revealing their inputs to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1149d",
   "metadata": {},
   "source": [
    "In the following example, we will look at one of the most popular library for federated learning Pysyft. Developed by openmined, pysyft was developed with the goal of secure and private machine learning. The Pysyft library is meant for you to write code that is capable of computing on data not owned on your local machine. In the following demo, we will be exploring the tool of remote execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262488d2",
   "metadata": {},
   "source": [
    "## Installation <a class=\"anchor\" id=\"installation\" />\n",
    "\n",
    "Before we dive into federated learning, let's install the necessary packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e892e573",
   "metadata": {},
   "source": [
    "#### 1. Install Conda environment\n",
    "`conda create --name duet python=3.8`\n",
    "Don't forget to activate your environment\n",
    "`conda activate duet`\n",
    "\n",
    "#### 2. Install necessary packages\n",
    "Inside your folder, create a txt file named 'requirements.txt' <br/>\n",
    "Then copy and past the following inside the txt file\n",
    "`\n",
    "numpy\n",
    "aiortc\n",
    "cryptography\n",
    "dataclasses\n",
    "dpcontracts\n",
    "flask\n",
    "forbiddenfruit>=0.1.3\n",
    "loguru\n",
    "matplotlib\n",
    "nest_asyncio\n",
    "packaging\n",
    "pandas\n",
    "protobuf\n",
    "pydagogy\n",
    "PyNaCl\n",
    "requests\n",
    "scikit-learn\n",
    "seaborn\n",
    "sqlitedict\n",
    "statsmodels\n",
    "typeguard\n",
    "typing-extensions # backport to older python 3\n",
    "websockets\n",
    "jupyter\n",
    "Jinja2<3.0\n",
    "`\n",
    "<br/>\n",
    "Afterwards, we can install the requirements by running the following command\n",
    "\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "#### 3. Install Pysyft\n",
    "`pip install syft==0.5.0`\n",
    "\n",
    "#### If you have errors\n",
    "- `ImportError: cannot import name 'soft_unicode' from 'markupsafe'`\n",
    "Resolve this by\n",
    "`python -m pip install markupsafe==2.0.1`\n",
    "- If you have the warning of CrytographyDeprecationWarning, you can ignore it for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca00360",
   "metadata": {},
   "source": [
    "# Pysyft Duet (Data Scientist) <a class = \"anchor\" id = \"duet\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b0a057",
   "metadata": {},
   "source": [
    "A peer-to-peer tool developed on top of the PySyft. It allows the data owner to expose their data to the data scientist, and the data scientist can manipulate the data through a zero-knowledge access mechanism. As data owners, you have the right to decide whether to allow the manipulation of data, you can deny or approve requests from the data scientists. As data scientists, you can develop new insights and train your model using the data owned by the data owners. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16992f5",
   "metadata": {},
   "source": [
    "Duet was used to demonstrate federated learning with PySyft without being deployed in the PyGrid ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ef7ff",
   "metadata": {},
   "source": [
    "1. To start, both the data owner and the data scientist will have to talk to one of the open grid network nodes hosted on AWS by OpenMined. The node will introduce the service to each other behind a firewall and help them connect peer to peer.\n",
    "\n",
    "2. The data owner need to first connect initiate and launch the duet server.\n",
    "\n",
    "3. With the server ID, the data scientist can join the duet session. This will give the data scientist a duet client id.\n",
    "\n",
    "4. The data owner will then need to enter the client id to complete the setup process.\n",
    "\n",
    "5. If all goes well, the data scientist and the data owner should be connected now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1828c3a2",
   "metadata": {},
   "source": [
    "## Duet Basics <a class = \"anchor\" id = \"basics\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9228852e",
   "metadata": {},
   "source": [
    "As the Data Scientist, you want to perform data science on data that is sitting in the Data Owner's Duet server in their Notebook.\n",
    "\n",
    "In order to do this, we must run the code that the Data Owner sends us, which importantly includes their Duet Session ID. The code will look like this, importantly with their real Server ID.\n",
    "\n",
    "import syft as sy\n",
    "duet = sy.duet('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "This will create a direct connection from my notebook to the remote Duet server. Once the connection is established all traffic is sent directly between the two nodes.\n",
    "\n",
    "Copy and paste the code or Server ID that the Data Owner gives you and run it in the cell below. It will return your Client ID which you must send to the Data Owner to enter into Duet so it can pair your notebooks.\n",
    "\n",
    "Make sure that the network_url you use is chosen from\n",
    "https://raw.githubusercontent.com/OpenMined/OpenGridNodes/master/network_address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c1801",
   "metadata": {},
   "source": [
    "### Step 2. Establish Connection with Data Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39444e60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Joining Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000/\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[95mSTEP 1:\u001b[0m Send the following Duet Client ID to your duet partner!\n",
      "â™«â™«â™« > Duet Client ID: \u001b[1m3406364123dfde0c6e7394b2167a9ef9\u001b[0m\n",
      "\n",
      "â™«â™«â™« > ...waiting for partner to connect...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/duet/lib/python3.9/site-packages/aiortc/rtcdtlstransport.py:211: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  _openssl_assert(lib.SSL_CTX_use_certificate(ctx, self._cert._x509) == 1)  # type: ignore\n",
      "/opt/anaconda3/envs/duet/lib/python3.9/site-packages/aiortc/rtcdtlstransport.py:186: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  value=certificate_digest(self._cert._x509),  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "duet = sy.join_duet(\"00eec93acc58f144d78a365705d42223\", network_url=\"http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d1c9bc",
   "metadata": {},
   "source": [
    "The `duet` variable is your reference to remote operations including supported libraries like torch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119052d6",
   "metadata": {},
   "source": [
    "<Strong>Step 3. Go to Data Owner Notebook <Strong/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260473b",
   "metadata": {},
   "source": [
    "### Step 4. Let's Search and Create Pointer to Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa696701",
   "metadata": {},
   "source": [
    "We can search for available data with their meta data(tags, decription and object type) with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355b39df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 2550b41ead684a24ac87a5dced4c5c6d&gt;</td>\n",
       "      <td>[grades]</td>\n",
       "      <td>This is a list of the grades of 6 people</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID      Tags  \\\n",
       "0  <UID: 2550b41ead684a24ac87a5dced4c5c6d>  [grades]   \n",
       "\n",
       "                                Description             object_type  \n",
       "0  This is a list of the grades of 6 people  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd60646",
   "metadata": {},
   "source": [
    "We can create a pointer to the data in the duet store. Note that this is the reference to the data, not the actual data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de2548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ptr = duet.store[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333f797",
   "metadata": {},
   "source": [
    "Now, let's do some computation remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac6739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_grade = data_ptr.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac42c6f",
   "metadata": {},
   "source": [
    "After we have done the computation, let's try and get the result from the data owner's server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b2926e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-19T16:37:24.260967-0600][CRITICAL][logger]][15013] You do not have permission to .get() Object with ID: <UID: 0e6d0efcb06441db9d958e2006f5cbc8>Please submit a request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Exception'>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    average_grade.get()\n",
    "except Exception:\n",
    "    print(Exception)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91621810",
   "metadata": {},
   "source": [
    "Looks like we need to request for permission from the data owner. We can do this by using the .request with your reasoning inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7463fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_grade.request(reason = \"please, I need it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42605aaa",
   "metadata": {},
   "source": [
    "<Strong>Step 5. Go to Data Owner Notebook <Strong/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3048bc",
   "metadata": {},
   "source": [
    "### Step 6. Let's try to get data from Data Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "916d174a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-19T16:37:35.877293-0600][CRITICAL][logger]][15013] You do not have permission to .get() Object with ID: <UID: 0e6d0efcb06441db9d958e2006f5cbc8>Please submit a request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Exception'>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    average_grade.get()\n",
    "except Exception:\n",
    "    print(Exception)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada22b6",
   "metadata": {},
   "source": [
    "Looks like our request didn't go through, let's create a new request with a better reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "653119c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_grade.request(\n",
    "    reason = \"I am a data scientist and I need to know the average of the students' grades for my analysis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddde4a",
   "metadata": {},
   "source": [
    "<Strong>Step 7. Go to Data Owner Notebook <Strong/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06df08",
   "metadata": {},
   "source": [
    "### Step 8. Get Result Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acdc6ad",
   "metadata": {},
   "source": [
    "We can check if there are still outstanding requests by running the following block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26edb372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet.requests.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6ec36",
   "metadata": {},
   "source": [
    "Looks like our request went through, now let's get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7d12183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(81.1667)\n"
     ]
    }
   ],
   "source": [
    "avg = average_grade.get()\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d67fd88",
   "metadata": {},
   "source": [
    "<Strong>Step 9. Go to Data Owner Notebook <Strong/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a982c8c",
   "metadata": {},
   "source": [
    "### Step 10. Machine Learning with Duet MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb17b69",
   "metadata": {},
   "source": [
    "# MNIST with Duet <a class = \"anchor\" id = \"mnist\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de566c4b",
   "metadata": {},
   "source": [
    "## Part 1: Connect to Remote Duet Server (Done above) <a class = \"anchor\" id = \"part1\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3fc40",
   "metadata": {},
   "source": [
    "## Part 2: Setting up Model and Data <a class = \"anchor\" id = \"part2\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3233e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11023020",
   "metadata": {},
   "source": [
    "Note that here, instead of traditionally inheriting from the nn.Module, we inherit from sy.Module, and we also need to pass in a variable called torch_ref when we constuct this network, the torch_ref will be used internally for any calls that would normally be to torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a81ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.conv1 = self.torch_ref.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = self.torch_ref.nn.Conv2d(32, 64, 3, 1) \n",
    "        self.dropout1 = self.torch_ref.nn.Dropout2d(0.25)\n",
    "        self.dropout2 = self.torch_ref.nn.Dropout2d(0.5)\n",
    "        self.fc1 = self.torch_ref.nn.Linear(9216, 128)\n",
    "        self.fc2 = self.torch_ref.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.torch_ref.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.torch_ref.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = self.torch_ref.nn.functional.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e29a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create the model and pass in our local copy of torch\n",
    "local_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c363708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define a few settings which are from the original MNIST example command-line args\n",
    "args = {\n",
    "    \"batch_size\": 64,\n",
    "    \"test_batch_size\": 1000,\n",
    "    \"epochs\": 3,\n",
    "    \"lr\": 0.01,\n",
    "    \"gamma\": 0.7,\n",
    "    \"no_cuda\": False,\n",
    "    \"dry_run\": False,\n",
    "    \"seed\": 42, \n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b113f88",
   "metadata": {},
   "source": [
    "Now we can send our local model to our partner's Duet server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "949f4e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = local_model.send(duet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4754a4",
   "metadata": {},
   "source": [
    "We can create an alias for our partner's torch called `remote_torch`, we do this so we can refer to the local torch as `torch` and any operations we want to do remotely as `remote_torch`. Remeber that the return values from `remote_torch` are Pointers, not the actual objects themselves. Keep in mind that you cannot mix the pointers with local torch objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "449f8936",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch = duet.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de6d2dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Data Owner device is cpu\n"
     ]
    }
   ],
   "source": [
    "# We can ask to see if the data owner has CUDA\n",
    "has_cuda = False\n",
    "has_cuda_ptr = remote_torch.cuda.is_available()\n",
    "has_cuda = bool(has_cuda_ptr.get(\n",
    "    request_block=True,\n",
    "    reason=\"To run test and inference locally\",\n",
    "    timeout_secs=20,  # change to something slower\n",
    "))\n",
    "print(has_cuda)\n",
    "\n",
    "use_cuda = not args[\"no_cuda\"] and has_cuda\n",
    "# now we can set the seed\n",
    "remote_torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "device = remote_torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"Data Owner device is {device.type.get()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef496461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have CUDA lets send our model to the GPU\n",
    "if has_cuda:\n",
    "    model.cuda(device)\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399792f4",
   "metadata": {},
   "source": [
    "Get parameters, setup an optimizer and scheduler just like you would do in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62ae0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b6f39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = remote_torch.optim.Adadelta(params, lr=args[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b90f76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = remote_torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=args[\"gamma\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0daa2",
   "metadata": {},
   "source": [
    "Next we need a training loop so we can improve our remote model. Since we want to train on remote data we should first check if the model is remote since we will be using remote_torch in this function. To check if a model is local or remote simply use the `.is_local` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af9d6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, torch_ref, train_loader, optimizer, epoch, args, train_data_length):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    train_batches = round((train_data_length / args[\"batch_size\"]) + 0.5)\n",
    "    print(f\"> Running train in {train_batches} batches\")\n",
    "    if model.is_local:\n",
    "        print(\"Training requires remote model\")\n",
    "        return\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data_ptr, target_ptr = data[0], data[1]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_ptr)\n",
    "        loss = torch_ref.nn.functional.nll_loss(output, target_ptr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.item()\n",
    "        train_loss = duet.python.Float(0)  # create a remote Float we can use for summation\n",
    "        train_loss += loss_item\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            local_loss = None\n",
    "            local_loss = loss_item.get(\n",
    "                reason=\"To evaluate training progress\",\n",
    "                request_block=True,\n",
    "                timeout_secs=5\n",
    "            )\n",
    "            if local_loss is not None:\n",
    "                print(\"Train Epoch: {} {} Loss: {:.4}\".format(epoch, batch_idx, local_loss))\n",
    "            else:\n",
    "                print(\"Train Epoch: {} {} ?\".format(epoch, batch_idx))\n",
    "        if batch_idx >= train_batches - 1:\n",
    "            print(\"batch_idx >= train_batches, breaking\")\n",
    "            break\n",
    "        if args[\"dry_run\"]:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e07bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_local(model, torch_ref, test_loader, test_data_length):\n",
    "    # download remote model\n",
    "    if not model.is_local:\n",
    "        local_model = model.get(\n",
    "            request_block=True,\n",
    "            reason=\"test evaluation\",\n",
    "            timeout_secs=5\n",
    "        )\n",
    "    else:\n",
    "        local_model = model\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "    print(f\"> Running test_local in {test_batches} batches\")\n",
    "    local_model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    with torch_ref.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            output = local_model(data)\n",
    "            iter_loss = torch_ref.nn.functional.nll_loss(output, target, reduction=\"sum\").item()\n",
    "            test_loss = test_loss + iter_loss\n",
    "            pred = output.argmax(dim=1)\n",
    "            total = pred.eq(target).sum().item()\n",
    "            correct += total\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "                \n",
    "            if batch_idx >= test_batches - 1:\n",
    "                print(\"batch_idx >= test_batches, breaking\")\n",
    "                break\n",
    "\n",
    "    accuracy = correct / test_data_length\n",
    "    print(f\"Test Set Accuracy: {100 * accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19fef361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# we need some transforms for the MNIST data set\n",
    "local_transform_1 = torchvision.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "local_transform_2 = torchvision.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "\n",
    "# compose our transforms\n",
    "local_transforms = torchvision.transforms.Compose([local_transform_1, local_transform_2])\n",
    "from syft.util import get_root_data_path\n",
    "# we will configure the test set here locally since we want to know if our Data Owner's\n",
    "# private training dataset will help us reach new SOTA results for our benchmark test set\n",
    "test_kwargs = {\n",
    "    \"batch_size\": args[\"test_batch_size\"],\n",
    "}\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(str(get_root_data_path()), train=False, download=True, transform=local_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,**test_kwargs)\n",
    "test_data_length = len(test_loader.dataset)\n",
    "print(test_data_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c6e97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some transforms for the MNIST data set\n",
    "remote_torchvision = duet.torchvision\n",
    "\n",
    "transform_1 = remote_torchvision.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "transform_2 = remote_torchvision.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "\n",
    "remote_list = duet.python.List()  # create a remote list to add the transforms to\n",
    "remote_list.append(transform_1)\n",
    "remote_list.append(transform_2)\n",
    "\n",
    "# compose our transforms\n",
    "transforms = remote_torchvision.transforms.Compose(remote_list)\n",
    "\n",
    "# The DO has kindly let us initialise a DataLoader for their training set\n",
    "train_kwargs = {\n",
    "    \"batch_size\": args[\"batch_size\"],\n",
    "}\n",
    "train_data_ptr = remote_torchvision.datasets.MNIST(str(get_root_data_path()), train=True, download=True, transform=transforms)\n",
    "train_loader_ptr = remote_torch.utils.data.DataLoader(train_data_ptr,**train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd0a1b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset size is: 60000\n"
     ]
    }
   ],
   "source": [
    "# normally we would not necessarily know the length of a remote dataset so lets ask for it\n",
    "# so we can pass that to our training loop and know when to stop\n",
    "def get_train_length(train_data_ptr):\n",
    "    train_data_length = len(train_data_ptr)\n",
    "    return train_data_length\n",
    "\n",
    "try:\n",
    "    if train_data_length is None:\n",
    "        train_data_length = get_train_length(train_data_ptr)\n",
    "except NameError:\n",
    "        train_data_length = get_train_length(train_data_ptr)\n",
    "\n",
    "print(f\"Training Dataset size is: {train_data_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb2603",
   "metadata": {},
   "source": [
    "## Part 3: Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cac2b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#args[\"dry_run\"] = True  # comment to do a full train\n",
    "print(\"Starting Training\")\n",
    "for epoch in range(1, args[\"epochs\"] + 1):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    # remote training on model with remote_torch\n",
    "    train(model, remote_torch, train_loader_ptr, optimizer, epoch, args, train_data_length)\n",
    "    # local testing on model with local torch\n",
    "    test_local(model, torch, test_loader, test_data_length)\n",
    "    scheduler.step()\n",
    "    epoch_end = time.time()\n",
    "    print(f\"Epoch time: {int(epoch_end - epoch_start)} seconds\")\n",
    "    if args[\"dry_run\"]:\n",
    "        break\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5676a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args[\"save_model\"]:\n",
    "    model.get(\n",
    "        request_block=True,\n",
    "        reason=\"test evaluation\",\n",
    "        timeout_secs=5\n",
    "    ).save(\"./duet_mnist.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799ad08",
   "metadata": {},
   "source": [
    "## Part 4: Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057bf847",
   "metadata": {},
   "source": [
    "Now we can use our model to do inference either remotely or locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66102959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def draw_image_and_label(image, label):\n",
    "    fig = plt.figure()\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"none\")\n",
    "    plt.title(\"Ground Truth: {}\".format(label))\n",
    "    \n",
    "def prep_for_inference(image):\n",
    "    image_batch = image.unsqueeze(0).unsqueeze(0)\n",
    "    image_batch = image_batch * 1.0\n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3de30da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_local(image, model):\n",
    "    if not model.is_local:\n",
    "        print(\"model is remote try .get()\")\n",
    "        return -1, torch.Tensor([-1])\n",
    "    image_tensor = torch.Tensor(prep_for_inference(image))\n",
    "    output = model(image_tensor)\n",
    "    preds = torch.exp(output)\n",
    "    local_y = preds\n",
    "    local_y = local_y.squeeze()\n",
    "    pos = local_y == max(local_y)\n",
    "    index = torch.nonzero(pos, as_tuple=False)\n",
    "    class_num = index.squeeze()\n",
    "    return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a660212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_remote(image, model):\n",
    "    if model.is_local:\n",
    "        print(\"model is local try .send()\")\n",
    "        return -1, remote_torch.Tensor([-1])\n",
    "    image_tensor_ptr = remote_torch.Tensor(prep_for_inference(image))\n",
    "    output = model(image_tensor_ptr)\n",
    "    preds = remote_torch.exp(output)\n",
    "    preds_result = preds.get(\n",
    "        request_block=True,\n",
    "        reason=\"To see a real world example of inference\",\n",
    "        timeout_secs=10\n",
    "    )\n",
    "    if preds_result is None:\n",
    "        print(\"No permission to do inference, request again\")\n",
    "        return -1, torch.Tensor([-1])\n",
    "    else:\n",
    "        # now we have the local tensor we can use local torch\n",
    "        local_y = torch.Tensor(preds_result)\n",
    "        local_y = local_y.squeeze()\n",
    "        pos = local_y == max(local_y)\n",
    "        index = torch.nonzero(pos, as_tuple=False)\n",
    "        class_num = index.squeeze()\n",
    "        return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e894181b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Test Image: 1192\n",
      "Displaying 1192 == 192 in Batch: 1/10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets grab something from the test set\n",
    "import random\n",
    "total_images = test_data_length # 10000\n",
    "index = random.randint(0, total_images)\n",
    "print(\"Random Test Image:\", index)\n",
    "count = 0\n",
    "batch = index // test_kwargs[\"batch_size\"]\n",
    "batch_index = index % int(total_images / len(test_loader))\n",
    "for tensor_ptr in test_loader:\n",
    "    data, target = tensor_ptr[0], tensor_ptr[1]\n",
    "    if batch == count:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "print(f\"Displaying {index} == {batch_index} in Batch: {batch}/{len(test_loader)}\")\n",
    "if batch_index > len(data):\n",
    "    batch_index = 0\n",
    "image_1 = data[batch_index].reshape((28, 28))\n",
    "label_1 = target[batch_index]\n",
    "draw_image_and_label(image_1, label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95d1f8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 4 Ground Truth: 9\n",
      "tensor([1.3907e-04, 5.6652e-04, 2.7458e-04, 4.1249e-03, 7.1542e-01, 3.2733e-03,\n",
      "        2.5919e-03, 2.5418e-02, 2.2922e-02, 2.2527e-01],\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# classify remote\n",
    "class_num, preds = classify_remote(image_1, model)\n",
    "print(f\"Prediction: {class_num} Ground Truth: {label_1}\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46a6e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting our model \n",
    "local_model = model.get(\n",
    "    request_block=True,\n",
    "    reason=\"To run test and inference locally\",\n",
    "    timeout_secs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "274eeea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 4 Ground Truth: 9\n",
      "tensor([0.0020, 0.0041, 0.0078, 0.0385, 0.2883, 0.1381, 0.0244, 0.0568, 0.2300,\n",
      "        0.2100], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# classify local\n",
    "class_num, preds = classify_local(image_1, local_model)\n",
    "print(f\"Prediction: {class_num} Ground Truth: {label_1}\")\n",
    "# here we can see the actual output\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2636e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also download an image from the web and run inference on that\n",
    "from PIL import Image, ImageEnhance\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import os\n",
    "def classify_url_image(image_url):\n",
    "    filename = os.path.basename(image_url)\n",
    "    os.system(f'curl -O {image_url}')\n",
    "    im = Image.open(filename)\n",
    "    im = PIL.ImageOps.invert(im)\n",
    "#     im = im.resize((28,28), Image.ANTIALIAS)\n",
    "    im = im.convert('LA')\n",
    "    enhancer = ImageEnhance.Brightness(im)\n",
    "    im = enhancer.enhance(3)\n",
    "\n",
    "\n",
    "    print(im.size)\n",
    "    fig = plt.figure()\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(im, cmap=\"gray\", interpolation=\"none\")\n",
    "    \n",
    "    # classify local\n",
    "    class_num, preds = classify_local(image_1, local_model)\n",
    "    print(f\"Prediction: {class_num}\")\n",
    "    print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "904fd996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 93)\n",
      "Prediction: 4\n",
      "tensor([0.0007, 0.0016, 0.0049, 0.0291, 0.4118, 0.0332, 0.0071, 0.0289, 0.0928,\n",
      "        0.3899], grad_fn=<SqueezeBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100  4655  100  4655    0     0   3819      0  0:00:01  0:00:01 --:--:--  3840\r",
      "100  4655  100  4655    0     0   3819      0  0:00:01  0:00:01 --:--:--  3840\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_url = \"https://raw.githubusercontent.com/kensanata/numbers/master/0018_CHXX/0/number-100.png\"\n",
    "classify_url_image(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c3839",
   "metadata": {},
   "source": [
    "## Where to go next? <a class = \"anchor\" id = \"next\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d8a60",
   "metadata": {},
   "source": [
    "* https://courses.openmined.org/\n",
    "    OpenMined(PySyft).\n",
    "    This is where I learned most of the federated learning material, and they have a great series on private AI technologies. Highly recommend.\n",
    "<hr/>\n",
    "* https://flower.dev/\n",
    "    Flower\n",
    "    Another federated learning framework.\n",
    "<hr/>\n",
    "* https://www.tensorflow.org/federated\n",
    "    Tensorflow Federated. Integrates very nicely with Tensorflow.\n",
    "<br/> <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b7a76",
   "metadata": {},
   "source": [
    "## Acknowledgement\n",
    "I would like to use this last section by thanking the support of my professor Yves Pauchard, and the DE Followship group. As well as the OpenMined Organization for innovating and building technology for the future, their work has inspired me to pursue more research and learning in the field of federated learning and I am extremely thankful. \n",
    "<br/> <br/>\n",
    "![MVPUrl](https://media.giphy.com/media/GVMhZwYv8U5NK/giphy.gif \"MVP\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6fd89d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
